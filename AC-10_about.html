<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AC-10 AI Music & Processing</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>AC-10 AI Music & Processing</h1>
        <img src="robomusic.png" alt="Team Logo" class="logo-left" />
        <img src="robomusic.png" alt="Team Logo" class="logo-right" />
    </header>
    <nav>
        <a href="index.html">Home</a>
        <a href="AC-10_about.html">About</a>
        <a href="AC-10_demo.html">Final Report</a>
        <a href="AC-10_future.html">Github</a>
    </nav>
    <main>
        <h2>About</h2>
        <p>This project explores the application of machine learning techniques to music classification and generation, with a focus on simulating human-like learning in music composition. Current methods have achieved success by relying on audio wave features such as Mel-Frequency Cepstral Coefficients (MFCC) for music analysis, but this research seeks to advance the field by utilizing MIDI data for model training. By leveraging MIDI, which captures the symbolic representation of music notes and timing, the project aims to enable the model to learn from musical patterns in a manner akin to human cognition. This approach emphasizes intuitive and anthropic learning processes, aiming to mimic the way a composer creates music through a learned vocabulary of musical themes and patterns. Expected outcomes involve a web-based demonstration and tutorial showcasing AI's capability to compose and recognize music, contributing to advancements in AI-driven music generation.</p>
        <h2>Background Info</h2>
        <p>
            As many of you know, AI is a machine simulation of human intelligence. It uses neural networks to learn and think. When “really” it's just doing computational attempts to minimize cost. Digital Music Processing is a software that allows you to record, edit, and produce audio that can also use virtual instruments to play MIDI files.
            When a human there are many ways to learn music, but the two most common approaches are Song Repetition and Pattern Recognition. This project will research how each learning approach affects music creation by AI. (List things listed)
            The exciting thing about this project is that neural networks can be “taught” in a similar way. With more neurons, the network can be trained on a dataset through memorization. With less, they can be trained in musical patterns. Once we have our data we’ll evaluate how the models trained on each approach compare to each other. We’ll be looking for and judging these models on several metrics like efficiency and creativity.
        </p>
    </main>
    <footer>
        <p>What you looking down here for?</p>
    </footer>
</body>
</html>
